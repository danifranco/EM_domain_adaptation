{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare data distribution and folders to be used with our DAMT-Net script\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### CHANGE THIS and run all ####\n",
        "\n",
        "# input data dir\n",
        "source_path = \"./mitochondria/\"\n",
        "# datasets (folder names) in the selected input data dir\n",
        "datasets = ['Lucchi++', 'VNC', 'Kasthuri++']\n",
        "\n",
        "# output data dir (where is going to be placed)\n",
        "destination_path = './datasets/mitochondria/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Input data distribution:\n",
        "\n",
        "for each dataset, for example 'VNC' ( data == 'VNC' )\n",
        "\n",
        "```\n",
        "    data/\n",
        "        |-- train/\n",
        "        |    |-- x/\n",
        "        |    |      training-0001.tif\n",
        "        |    |      ...\n",
        "        |    |-- y/\n",
        "        |    |      training_groundtruth-0001.tif\n",
        "        |    |        ...\n",
        "        |-- test/\n",
        "        |    |-- x/\n",
        "        |    |      testing-0001.tif\n",
        "        |    |      ...\n",
        "        |    |-- y/\n",
        "        |    |      testing_groundtruth-0001.tif\n",
        "        |    |      ...\n",
        "```\n",
        "\n",
        "Output data distribution: \n",
        "\n",
        "```\n",
        "    data/\n",
        "        |-- train/\n",
        "        |    |-- file_list.txt\n",
        "        |    |-- x/\n",
        "        |    |      training-0001.tif\n",
        "        |    |      ...\n",
        "        |    |-- y/\n",
        "        |    |      training_groundtruth-0001.tif\n",
        "        |    |        ...\n",
        "        |-- test/\n",
        "        |    ...\n",
        "        |-- train_val/\n",
        "        |    ...\n",
        "        |-- train_val_test/\n",
        "        |    ...\n",
        "        |-- val/\n",
        "        |    ...\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def set_seed(seedValue=42):\n",
        "  \"\"\"Sets the seed on multiple python modules to obtain results as\n",
        "  reproducible as possible.\n",
        "  Args:\n",
        "  seedValue (int, optional): seed value.\n",
        "  \"\"\"\n",
        "  np.random.seed(seed=seedValue)\n",
        "  os.environ[\"PYTHONHASHSEED\"]=str(seedValue)\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.util import img_as_ubyte\n",
        "from skimage import io\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "def get_xy_image_list(dir):\n",
        "    if dir[-1]=='/':\n",
        "        dir = dir[:-1]\n",
        "    # Paths to the training images and their corresponding labels\n",
        "    train_input_path = dir + '/x/*.*'\n",
        "    train_label_path = dir + '/y/*.*'\n",
        "\n",
        "    # Read the list of file names\n",
        "    train_input_filenames = glob(train_input_path)\n",
        "    train_input_filenames.sort()\n",
        "\n",
        "    train_label_filenames = glob(train_label_path)\n",
        "    train_label_filenames.sort()\n",
        "\n",
        "    #print( 'Input images loaded: ' + str( len(train_input_filenames)) )\n",
        "    #print( 'Label images loaded: ' + str( len(train_label_filenames)) )\n",
        "\n",
        "    # read training images and labels\n",
        "    train_img = [ img_as_ubyte( np.array( io.imread( x ), dtype='uint8') ) for x in train_input_filenames ]\n",
        "    train_lbl = [ img_as_ubyte( np.array( io.imread( x ), dtype='uint8') ) for x in train_label_filenames ]\n",
        "    filenames = []\n",
        "    for x in train_label_filenames:\n",
        "        x = os.path.basename(x)\n",
        "        name, ext = os.path.splitext(x)\n",
        "        filenames.append(name)\n",
        "    \n",
        "    return train_img, train_lbl, filenames\n",
        "\n",
        "def save_images(imgs, dst_path, name_prefix, fnames, format='.png', convert=''):\n",
        "    for i, img in enumerate(imgs):\n",
        "        im = Image.fromarray(img)\n",
        "        if convert != '':\n",
        "            im = im.convert(convert)\n",
        "        im.save( os.path.join(dst_path, fnames[i] + name_prefix + format), quality=100)\n",
        "\n",
        "def create_dir(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create main sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lucchi++\n",
            " train\n",
            " test\n",
            "VNC\n",
            " train\n",
            " test\n",
            "Kasthuri++\n",
            " train\n",
            " test\n"
          ]
        }
      ],
      "source": [
        "create_dir(destination_path)\n",
        "\n",
        "for ds_name in datasets:\n",
        "    direc = os.path.join(source_path, ds_name)\n",
        "\n",
        "    print(ds_name)\n",
        "\n",
        "    print(\" train\")\n",
        "    fold = \"train\"\n",
        "    train_img, train_lbl, train_fnames = get_xy_image_list(os.path.join(direc,\"train\"))\n",
        "\n",
        "    out_img_path = os.path.join(destination_path, ds_name, fold, \"x\" )\n",
        "    out_mask_path = os.path.join(destination_path, ds_name, fold, \"y\" )\n",
        "    create_dir(out_img_path)\n",
        "    create_dir(out_mask_path)\n",
        "    save_images(train_img, out_img_path, ds_name, train_fnames, format='.png')\n",
        "    save_images(train_lbl, out_mask_path, ds_name, train_fnames, format='.png')\n",
        "\n",
        "    print(\" test\")\n",
        "    fold = \"test\"\n",
        "    test_img, test_lbl, test_fnames = get_xy_image_list(os.path.join(direc,\"test\"))\n",
        "\n",
        "    out_img_path = os.path.join(destination_path, ds_name, fold, \"x\")\n",
        "    out_mask_path = os.path.join(destination_path, ds_name, fold, \"y\" )\n",
        "    create_dir(out_img_path)\n",
        "    create_dir(out_mask_path)\n",
        "    save_images(test_img, out_img_path, ds_name, test_fnames, format='.png')\n",
        "    save_images(test_lbl, out_mask_path, ds_name, test_fnames, format='.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### make splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lucchi++\n",
            "VNC\n",
            "Kasthuri++\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import os\n",
        "def train_val_split(train_path, val_path, size = 0.1):\n",
        "    create_dir(os.path.join(val_path,'x'))\n",
        "    create_dir(os.path.join(val_path,'y'))\n",
        "\n",
        "    x_set = glob(os.path.join(train_path,\"x/*\"))\n",
        "    y_set = glob(os.path.join(train_path,\"y/*\"))\n",
        "\n",
        "    x_set.sort()\n",
        "    y_set.sort()\n",
        "\n",
        "    assert len(x_set) != 0, \"There are no images\"  \n",
        "    assert len(x_set) == len(y_set), \"There is different ammount of images and masks x:\" + str(len(x_set)) + \", y:\" + str(len(y_set))\n",
        "\n",
        "    indices = [i for i in range(len(x_set))]\n",
        "    _, val_img_indices = train_test_split(\n",
        "        indices, \n",
        "        test_size=size,\n",
        "        random_state=42)\n",
        "\n",
        "    shutil.copytree(train_path, train_path + \"_val/\")\n",
        "    \n",
        "    for i in val_img_indices:\n",
        "        x = x_set[i]\n",
        "        y = y_set[i]\n",
        "        shutil.move(x, os.path.join(val_path, 'x', os.path.basename(x)))\n",
        "        shutil.move(y, os.path.join(val_path, 'y', os.path.basename(y)))\n",
        "\n",
        "for ds in datasets:\n",
        "    print(ds)\n",
        "    train_val_split(\n",
        "        os.path.join(destination_path, ds, \"train\"),\n",
        "        os.path.join(destination_path, ds, \"val\"), \n",
        "        size=0.1)# size 0.1 == 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lucchi++\n",
            "VNC\n",
            "Kasthuri++\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def combine_folders(train_path, test_path, out_path):\n",
        "    shutil.copytree(train_path, out_path)\n",
        "\n",
        "    x_set = glob(os.path.join(test_path,\"x/*\"))\n",
        "    y_set = glob(os.path.join(test_path,\"y/*\"))\n",
        "    x_set.sort()\n",
        "    y_set.sort()\n",
        "    assert len(x_set) != 0, \"There are no images in Test\"  \n",
        "    assert len(x_set) == len(y_set), \"There is different ammount of images on test and masks x:\" + str(len(x_set)) + \", y:\" + str(len(y_set))\n",
        "    \n",
        "    for i in range(len(x_set)):\n",
        "        x = x_set[i]\n",
        "        y = y_set[i]\n",
        "        shutil.copy(x, os.path.join(out_path, 'x', 'test_' + os.path.basename(x)))\n",
        "        shutil.copy(y, os.path.join(out_path, 'y', 'test_' + os.path.basename(y)))\n",
        "\n",
        "for ds in datasets:\n",
        "    print(ds)\n",
        "    combine_folders(\n",
        "        os.path.join(destination_path, ds, \"train_val\"),\n",
        "        os.path.join(destination_path, ds, \"test\"), \n",
        "        os.path.join(destination_path, ds, \"train_val_test\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./datasets/mitochondria\\Kasthuri++\\test\\\n",
            "./datasets/mitochondria\\Kasthuri++\\train\\\n",
            "./datasets/mitochondria\\Kasthuri++\\train_val\\\n",
            "./datasets/mitochondria\\Kasthuri++\\train_val_test\\\n",
            "./datasets/mitochondria\\Kasthuri++\\val\\\n",
            "./datasets/mitochondria\\Lucchi++\\test\\\n",
            "./datasets/mitochondria\\Lucchi++\\train\\\n",
            "./datasets/mitochondria\\Lucchi++\\train_val\\\n",
            "./datasets/mitochondria\\Lucchi++\\train_val_test\\\n",
            "./datasets/mitochondria\\Lucchi++\\val\\\n",
            "./datasets/mitochondria\\VNC\\test\\\n",
            "./datasets/mitochondria\\VNC\\train\\\n",
            "./datasets/mitochondria\\VNC\\train_val\\\n",
            "./datasets/mitochondria\\VNC\\train_val_test\\\n",
            "./datasets/mitochondria\\VNC\\val\\\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "\n",
        "def equal_rename_xy(path):\n",
        "    x = glob(path+\"x/*\")\n",
        "    y = glob(path+\"y/*\")\n",
        "\n",
        "    x.sort()\n",
        "    y.sort()\n",
        "    \n",
        "    filenames = []\n",
        "    for (x_path, y_path) in zip(x,y):\n",
        "        x_name = os.path.basename(x_path)\n",
        "        y_dir = os.path.dirname(y_path)\n",
        "        os.rename(y_path, os.path.join(y_dir, x_name))\n",
        "        filenames.append(x_name)\n",
        "    return filenames\n",
        "\n",
        "dirs = glob(destination_path + \"*/*/\")\n",
        "for dir in dirs:\n",
        "    print(dir)\n",
        "    names = equal_rename_xy(dir)\n",
        "    f = open(dir + \"file_list.txt\", \"w\")\n",
        "    #f.write('\\n'.join(names) + '\\n')\n",
        "    f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4Ew3GyS-l_d2",
        "Yicr_LOZ_Mp9",
        "qZYVAAtINQJ_",
        "OTvShF72h-4Y",
        "hbsdA5QAqWHl",
        "-gqnqcUzqQag",
        "du6R86IeeeEe",
        "eJYXxK-GYa1W",
        "nS-5hJFq3mw0",
        "kZCQZOXi7XQq",
        "xVMzbIZLcyEF",
        "iBzb9oja7KbL",
        "CpdG2ZZZK0uO",
        "_cd1oa_3HeqF",
        "hgYFeGr-B98_",
        "ZsSNWsVD20H6",
        "YA1UdPPV20H9",
        "cmyLDkczChtf",
        "ojDN518uXG0t",
        "91y9sVITNed1",
        "3wD0M6N1wR5S",
        "uEcM7GxIXG0x"
      ],
      "name": "EM_image_Segmentation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "9357fc209d6540ae373dc5ab9accaf1787f9762be9927163953c6f99d41aae73"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit ('pytorch_env': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
