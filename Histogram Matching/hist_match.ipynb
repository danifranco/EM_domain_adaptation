{"cells":[{"cell_type":"markdown","metadata":{"id":"luSS6e7lSL0H"},"source":["# Histogram matching"]},{"cell_type":"markdown","metadata":{"id":"TjS4Fi_Dbu9u"},"source":["## Funciones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nuGZtybsbu9u"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from skimage.util import img_as_ubyte\n","from skimage import io\n","from glob import glob\n","import numpy as np\n","import random\n","from PIL import Image\n","from sklearn.linear_model import LinearRegression\n","import os\n","\n","def get_image_list(dir):\n","    '''\n","    Reads all the images in the specified directory and returns a list of numpy arrays representing the\n","    images\n","\n","    Args:\n","      dir: The directory that contains the images.\n","\n","    Returns:\n","      A list of numpy arrays representing the images.\n","    '''\n","    if dir[-1]=='/':\n","        dir = dir[:-1]\n","    train_label_path = dir + '/*.*'\n","\n","    train_label_filenames = glob(train_label_path)\n","    train_label_filenames.sort()\n","\n","    print( 'Label images loaded: ' + str( len(train_label_filenames)) )\n","\n","    # read training images and labels\n","    train_lbl = [ img_as_ubyte( np.array(io.imread( x, as_gray=True ), dtype='uint8') ) for x in train_label_filenames ]\n","    return train_lbl\n","\n","def save_images(imgs, dst_path, name_prefix, fnames, format='.png', convert=''):\n","    '''\n","    Save images to disk\n","\n","    Args:\n","      imgs: The list of images to be saved.\n","      dst_path: the destination directory where the images will be saved.\n","      name_prefix: The prefix of the file name.\n","      fnames: The filenames of the images to be saved.\n","      format: The format of the output images. Defaults to .png\n","      convert: 'L' for greyscale, 'RGB' for color, or '' for nothing.\n","    '''\n","    for i, img in enumerate(imgs):\n","        im = Image.fromarray(img)\n","        if convert != '':\n","            im = im.convert(convert)\n","        im.save( os.path.join(dst_path, fnames[i] + name_prefix + format), quality=100, subsampling=0)\n","\n","def create_dir(dir):\n","    '''\n","    Create a directory if it doesn't exist\n","\n","    Args:\n","      dir: The directory where the model will be saved.\n","    '''\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)"]},{"cell_type":"markdown","metadata":{"id":"Y3MbPxPYbu9w"},"source":["## Histogram matching Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZkPMrX9Ibu9w"},"outputs":[],"source":["# apply histogram matching to any image (not mask) from sorce dataset, using target mean histogram\n","# this histogram matching, match the given cumulative histogram to target cumulative histogram\n","from sklearn.linear_model import LinearRegression\n","\n","def histogram_matching(target_imgs, apply_prob):\n","    '''\n","    Given a set of images, it will obtain their mean histogram. The number of 0s of this histogram will be predicted\n","     using Linear regression, with the real number of 1 and 2. It returns a function that apply histogram matching,\n","     using the calculated histogram. This returned function will apply a random histogram matching to each image with probability\n","     apply_prob.\n","\n","    Args:\n","      target_imgs: the target domain images, from which mean histogram will be obtained (with predicted number of 0s)\n","      apply_prob: probability of applying the histogram matching\n","\n","    Returns:\n","      A function that takes an image as input and returns a modified image or the original image, with\n","    the given probability.\n","    '''\n","\n","    LR = LinearRegression()\n","    hist_mean,_ = np.histogram(np.array(target_imgs).ravel(), bins=np.arange(256))\n","    reg = LR.fit(np.reshape([1,2],(-1,1)), np.reshape(hist_mean[1:3],(-1,1))) # use next 2 values to predict using LR\n","    hist_mean[0] = max(0, float(reg.predict(np.reshape([0,],(-1,1))))) # predict 0 values (due to padding)\n","    hist_mean = hist_mean / np.array(target_imgs).shape[0] # number of images\n","\n","    # calculate normalized quantiles\n","    #tmpl_size = target_imgs[0].size # once 0 value is predicted, the sum of pixels are not the same as the one in the image, so size is no longer useful\n","    tmpl_size = np.sum(hist_mean)\n","    tmpl_quantiles = np.cumsum(hist_mean) / tmpl_size\n","\n","    # based on scikit implementation.\n","    # source: https://github.com/scikit-image/scikit-image/blob/v0.18.0/skimage/exposure/histogram_matching.py#L22-L70\n","    def _match_cumulative_cdf(source, tmpl_quantiles):\n","        src_values, src_unique_indices, src_counts = np.unique(source.ravel(),\n","                                                            return_inverse=True,\n","                                                            return_counts=True)\n","\n","        # calculate normalized quantiles\n","        # replace number of 0s with lineal regression in order to avoid padding\n","        if src_values[0] == 0:\n","            if src_values[:3].tolist() == [0,1,2]:\n","                reg = LR.fit(np.reshape([1,2],(-1,1)), np.reshape(src_counts[1:3],(-1,1))) # use next 2 values to predict using LR\n","                pred_0 = max( 0, float(reg.predict(np.reshape([0,],(-1,1)))) ) # predict 0 values (due to padding)\n","            else:\n","                # images can be completely black\n","                pred_0 = 1 if len(src_counts) == 1 else 0 # 1 if completely black, else 0\n","\n","            src_size = (source.size - src_counts[0]) + pred_0 # more efficient than 'sum(src_counts)'\n","            src_counts[0] = pred_0 # replace histogram 0s with predictted value\n","        else:\n","            src_size = source.size # number of pixels\n","\n","        src_quantiles = np.cumsum(src_counts) / src_size # normalize\n","        interp_a_values = np.interp(src_quantiles, tmpl_quantiles, np.arange(len(tmpl_quantiles)))\n","        if src_values[0] == 0:\n","            interp_a_values[0] = 0 # we want to keep 0s, (padding)\n","\n","        return interp_a_values[src_unique_indices].reshape(source.shape)\n","\n","    def random_histogram_matching(image):\n","        if random.random() < apply_prob:\n","            result = _match_cumulative_cdf(image, tmpl_quantiles)\n","        else:\n","            result = image\n","        return result\n","\n","    return random_histogram_matching\n"]},{"cell_type":"markdown","metadata":{"id":"tSCcbdFCbu9x"},"source":["## Apply"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlpnBV7Rbu9x"},"outputs":[],"source":["# directory with all datasets\n","data_path = \"./mitochondria/\"\n","# dataset names inside the data_path (all combinations will be computed)\n","datasets = ['Lucchi++', 'VNC', 'Kasthuri++']\n","# directory where results are going to be stored\n","out_dir = \"./mitochondria/hist_match/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-giYUG8bu9y","outputId":"fc3694e4-ff3c-4090-b87d-9e25a43e6fb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," S: Lucchi++\tT: VNC\n","\n","Label images loaded: 20\n","Label images loaded: 20\n","\n"," S: Lucchi++\tT: Kasthuri++\n","\n","Label images loaded: 85\n","Label images loaded: 75\n","\n"," S: VNC\tT: Lucchi++\n","\n","Label images loaded: 165\n","Label images loaded: 165\n","\n"," S: VNC\tT: Kasthuri++\n","\n","Label images loaded: 85\n","Label images loaded: 75\n","\n"," S: Kasthuri++\tT: Lucchi++\n","\n","Label images loaded: 165\n","Label images loaded: 165\n","\n"," S: Kasthuri++\tT: VNC\n","\n","Label images loaded: 20\n","Label images loaded: 20\n"]}],"source":["for source in datasets:\n","    for target in datasets:\n","        if source == target:\n","            continue\n","\n","        print(\"\\n S: {}\\tT: {}\\n\".format(source, target))\n","\n","        tx = get_image_list(os.path.join(data_path, target ,\"train\", \"x\"))\n","        tx2 = get_image_list(os.path.join(data_path, target ,\"test\", \"x\"))\n","        # train and test may have different sizes, so i concatenate flattened vectors (this does not affect the histogram matching)\n","        target_trainTest_flat = np.concatenate( (np.array(tx).ravel(), np.array(tx2).ravel()) ) # for histogram matching\n","        hist_match = histogram_matching(target_trainTest_flat, 1)\n","\n","        for p in ['train', 'test']:\n","            in_dir = os.path.join(data_path, source, p )\n","            for t in ['x', 'y']:\n","                # Paths to the training images and their corresponding labels\n","                train_input_path = os.path.join(in_dir, t, '*.*')\n","\n","                # Read the list of file names\n","                train_input_filenames = glob(train_input_path)\n","                train_input_filenames.sort()\n","\n","                # read training images and labels\n","                sx = [ img_as_ubyte( np.array(io.imread( x, as_gray=True ), dtype='uint8') ) for x in train_input_filenames ]\n","\n","                if t == 'x':\n","                    hm_sx = [hist_match(t) for t in sx]\n","                else:\n","                    hm_sx = sx\n","\n","                train_input_filenames = [os.path.splitext(os.path.basename(x))[0] for x in train_input_filenames]\n","\n","                out_path = os.path.join(out_dir, source, source+\"_s-t_\"+target, p, t)\n","                create_dir(out_path)\n","                try:\n","                    save_images(hm_sx, out_path, '', train_input_filenames, format='.png')\n","                except:\n","                    save_images(hm_sx, out_path, '', train_input_filenames, format='.png', convert='L')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"interpreter":{"hash":"debdf61127670479a47cb26a9619f3431a8c0552ea0e08a6ebaef695806b6b0b"},"kernelspec":{"display_name":"Python 3.9.6 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}